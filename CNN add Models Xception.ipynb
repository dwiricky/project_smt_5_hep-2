{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afraid-reception",
   "metadata": {
    "papermill": {
     "duration": 5.695448,
     "end_time": "2021-05-18T03:49:39.220397",
     "exception": false,
     "start_time": "2021-05-18T03:49:33.524949",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Dense, Activation,Dropout,Conv2D, MaxPooling2D,BatchNormalization, Flatten,Input\n",
    "from tensorflow.keras.optimizers import Adam, Adamax\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import Model, load_model, Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "import os\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaptive-serve",
   "metadata": {
    "papermill": {
     "duration": 0.015623,
     "end_time": "2021-05-18T03:49:39.253552",
     "exception": false,
     "start_time": "2021-05-18T03:49:39.237929",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### iterate through the folders to create a dataframe of the form filepaths labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "patent-debate",
   "metadata": {
    "papermill": {
     "duration": 0.411876,
     "end_time": "2021-05-18T03:49:39.681304",
     "exception": false,
     "start_time": "2021-05-18T03:49:39.269428",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           filepaths      labels\n",
      "0  D:\\Kuliah\\Semester 5\\Project\\Dataset\\New folde...  batik-bali\n",
      "1  D:\\Kuliah\\Semester 5\\Project\\Dataset\\New folde...  batik-bali\n",
      "2  D:\\Kuliah\\Semester 5\\Project\\Dataset\\New folde...  batik-bali\n",
      "3  D:\\Kuliah\\Semester 5\\Project\\Dataset\\New folde...  batik-bali\n",
      "4  D:\\Kuliah\\Semester 5\\Project\\Dataset\\New folde...  batik-bali\n",
      "labels\n",
      "batik-bali           50\n",
      "batik-keraton        50\n",
      "batik-sogan          50\n",
      "batik-sidoluhur      50\n",
      "batik-priangan       50\n",
      "batik-pekalongan     50\n",
      "batik-parang         50\n",
      "batik-betawi         50\n",
      "batik-lasem          50\n",
      "batik-gentongan      50\n",
      "batik-garutan        50\n",
      "batik-ciamis         50\n",
      "batik-cendrawasih    50\n",
      "batik-celup          50\n",
      "batik-tambal         50\n",
      "batik-ceplok         48\n",
      "batik-sekar          47\n",
      "batik-megamendung    46\n",
      "batik-sidomukti      46\n",
      "batik-kawung         45\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "sdir=r'D:\\Kuliah\\Semester 5\\Project\\Dataset'\n",
    "\n",
    "\n",
    "filepaths=[]\n",
    "labels=[]\n",
    "classlist=os.listdir(sdir)\n",
    "for klass in classlist:\n",
    "    classpath=os.path.join(sdir,klass)\n",
    "    if os.path.isdir(classpath):\n",
    "        flist=os.listdir(classpath)\n",
    "        for f in flist:\n",
    "            fpath=os.path.join(classpath,f)\n",
    "            filepaths.append(fpath)\n",
    "            labels.append(klass)                   \n",
    "Fseries= pd.Series(filepaths, name='filepaths')\n",
    "Lseries=pd.Series(labels, name='labels')    \n",
    "df=pd.concat([Fseries, Lseries], axis=1)\n",
    "print (df.head())\n",
    "print (df['labels'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "western-television",
   "metadata": {
    "papermill": {
     "duration": 0.016063,
     "end_time": "2021-05-18T03:49:39.713849",
     "exception": false,
     "start_time": "2021-05-18T03:49:39.697786",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### split df into train_df, test_df and valid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "endangered-radio",
   "metadata": {
    "papermill": {
     "duration": 0.029986,
     "end_time": "2021-05-18T03:49:39.759808",
     "exception": false,
     "start_time": "2021-05-18T03:49:39.729822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df length:  785   test_df length:  98   valid_df length:  99\n"
     ]
    }
   ],
   "source": [
    "train_split=.8\n",
    "test_split=.1\n",
    "dummy_split=test_split/(1-train_split)\n",
    "train_df, dummy_df=train_test_split(df, train_size=train_split, shuffle=True, random_state=123)\n",
    "test_df, valid_df=train_test_split(dummy_df, train_size=dummy_split, shuffle=True, random_state=123)\n",
    "print ('train_df length: ', len(train_df), '  test_df length: ', len(test_df), '  valid_df length: ', len(valid_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signed-madonna",
   "metadata": {
    "papermill": {
     "duration": 0.01636,
     "end_time": "2021-05-18T03:49:39.792578",
     "exception": false,
     "start_time": "2021-05-18T03:49:39.776218",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### create train, test, valid  generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "robust-quarterly",
   "metadata": {
    "papermill": {
     "duration": 2.694365,
     "end_time": "2021-05-18T03:49:42.503459",
     "exception": false,
     "start_time": "2021-05-18T03:49:39.809094",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test batch size:  49   test steps:  2\n",
      "Found 785 validated image filenames belonging to 20 classes.\n",
      "Found 99 validated image filenames belonging to 20 classes.\n",
      "Found 98 validated image filenames belonging to 20 classes.\n",
      "['batik-bali', 'batik-betawi', 'batik-celup', 'batik-cendrawasih', 'batik-ceplok', 'batik-ciamis', 'batik-garutan', 'batik-gentongan', 'batik-kawung', 'batik-keraton', 'batik-lasem', 'batik-megamendung', 'batik-parang', 'batik-pekalongan', 'batik-priangan', 'batik-sekar', 'batik-sidoluhur', 'batik-sidomukti', 'batik-sogan', 'batik-tambal']\n"
     ]
    }
   ],
   "source": [
    "height=224\n",
    "width=224\n",
    "channels=3\n",
    "batch_size=64\n",
    "\n",
    "img_shape=(height, width, channels)\n",
    "img_size=(height, width)\n",
    "length=len(test_df)\n",
    "test_batch_size=sorted([int(length/n) for n in range(1,length+1) if length % n ==0 and length/n<=80],reverse=True)[0]  \n",
    "test_steps=int(length/test_batch_size)\n",
    "print ( 'test batch size: ' ,test_batch_size, '  test steps: ', test_steps)\n",
    "\n",
    "gen=ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    )\n",
    "train_gen=gen.flow_from_dataframe( train_df, x_col='filepaths', y_col='labels', target_size=img_size, class_mode='categorical',\n",
    "                                    color_mode='rgb', shuffle=True, batch_size=batch_size)\n",
    "\n",
    "validgen=ImageDataGenerator(rescale=1./255)\n",
    "valid_gen=validgen.flow_from_dataframe( valid_df, x_col='filepaths', y_col='labels', target_size=img_size, class_mode='categorical',\n",
    "                                    color_mode='rgb', shuffle=True, batch_size=batch_size)\n",
    "\n",
    "testgen=ImageDataGenerator(rescale=1./255)\n",
    "test_gen=testgen.flow_from_dataframe( test_df, x_col='filepaths', y_col='labels', target_size=img_size, class_mode='categorical',\n",
    "                                    color_mode='rgb', shuffle=False, batch_size=test_batch_size)\n",
    "\n",
    "classes=list(train_gen.class_indices.keys())\n",
    "print (classes)\n",
    "class_count=len(classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funny-tobago",
   "metadata": {
    "papermill": {
     "duration": 0.017787,
     "end_time": "2021-05-18T03:49:42.656153",
     "exception": false,
     "start_time": "2021-05-18T03:49:42.638366",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### create function to show some image examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "coated-bosnia",
   "metadata": {
    "papermill": {
     "duration": 0.02745,
     "end_time": "2021-05-18T03:49:42.701601",
     "exception": false,
     "start_time": "2021-05-18T03:49:42.674151",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_image_samples(gen):\n",
    "    test_dict=test_gen.class_indices\n",
    "    classes=list(test_dict.keys())    \n",
    "    images,labels=next(gen) # get a sample batch from the generator \n",
    "    plt.figure(figsize=(20, 20))\n",
    "    length=len(labels)\n",
    "    if length<25:   #show maximum of 25 images\n",
    "        r=length\n",
    "    else:\n",
    "        r=25\n",
    "    for i in range(r):\n",
    "        plt.subplot(5, 5, i + 1)\n",
    "        image=images[i]\n",
    "        plt.imshow(image)\n",
    "        index=np.argmax(labels[i])\n",
    "        class_name=classes[index]\n",
    "        plt.title(class_name, color='blue', fontsize=16)\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "concerned-viewer",
   "metadata": {
    "papermill": {
     "duration": 2.911847,
     "end_time": "2021-05-18T03:49:45.631353",
     "exception": false,
     "start_time": "2021-05-18T03:49:42.719506",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "UnidentifiedImageError",
     "evalue": "cannot identify image file <_io.BytesIO object at 0x0000020EDC62DD50>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnidentifiedImageError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mshow_image_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_gen\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[5], line 4\u001b[0m, in \u001b[0;36mshow_image_samples\u001b[1;34m(gen)\u001b[0m\n\u001b[0;32m      2\u001b[0m test_dict\u001b[38;5;241m=\u001b[39mtest_gen\u001b[38;5;241m.\u001b[39mclass_indices\n\u001b[0;32m      3\u001b[0m classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(test_dict\u001b[38;5;241m.\u001b[39mkeys())    \n\u001b[1;32m----> 4\u001b[0m images,labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# get a sample batch from the generator \u001b[39;00m\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m20\u001b[39m))\n\u001b[0;32m      6\u001b[0m length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(labels)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\batik\\lib\\site-packages\\keras\\preprocessing\\image.py:156\u001b[0m, in \u001b[0;36mIterator.__next__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\batik\\lib\\site-packages\\keras\\preprocessing\\image.py:168\u001b[0m, in \u001b[0;36mIterator.next\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    165\u001b[0m     index_array \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_generator)\n\u001b[0;32m    166\u001b[0m \u001b[38;5;66;03m# The transformation of images is not under thread lock\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;66;03m# so it can be done in parallel\u001b[39;00m\n\u001b[1;32m--> 168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_batches_of_transformed_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex_array\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\batik\\lib\\site-packages\\keras\\preprocessing\\image.py:370\u001b[0m, in \u001b[0;36mBatchFromFilesMixin._get_batches_of_transformed_samples\u001b[1;34m(self, index_array)\u001b[0m\n\u001b[0;32m    368\u001b[0m filepaths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepaths\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(index_array):\n\u001b[1;32m--> 370\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mimage_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_img\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    371\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilepaths\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    372\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolor_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    373\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    374\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    375\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_aspect_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeep_aspect_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    376\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    377\u001b[0m     x \u001b[38;5;241m=\u001b[39m image_utils\u001b[38;5;241m.\u001b[39mimg_to_array(img, data_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_format)\n\u001b[0;32m    378\u001b[0m     \u001b[38;5;66;03m# Pillow images should be closed after `load_img`,\u001b[39;00m\n\u001b[0;32m    379\u001b[0m     \u001b[38;5;66;03m# but not PIL images.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\batik\\lib\\site-packages\\keras\\utils\\image_utils.py:423\u001b[0m, in \u001b[0;36mload_img\u001b[1;34m(path, grayscale, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[0;32m    421\u001b[0m         path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(path\u001b[38;5;241m.\u001b[39mresolve())\n\u001b[0;32m    422\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m--> 423\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mpil_image\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBytesIO\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    425\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    426\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath should be path-like or io.BytesIO\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    427\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, not \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mtype\u001b[39m(path))\n\u001b[0;32m    428\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\batik\\lib\\site-packages\\PIL\\Image.py:3280\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3278\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message)\n\u001b[0;32m   3279\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot identify image file \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (filename \u001b[38;5;28;01mif\u001b[39;00m filename \u001b[38;5;28;01melse\u001b[39;00m fp)\n\u001b[1;32m-> 3280\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m UnidentifiedImageError(msg)\n",
      "\u001b[1;31mUnidentifiedImageError\u001b[0m: cannot identify image file <_io.BytesIO object at 0x0000020EDC62DD50>"
     ]
    }
   ],
   "source": [
    "show_image_samples(train_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "damaged-flight",
   "metadata": {
    "papermill": {
     "duration": 0.04921,
     "end_time": "2021-05-18T03:49:45.935993",
     "exception": false,
     "start_time": "2021-05-18T03:49:45.886783",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec60a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model=tf.keras.applications.Xception(include_top=False, weights=\"imagenet\",input_tensor=Input(shape=(224,224,3))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb622b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c945d250",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleasant-growth",
   "metadata": {
    "papermill": {
     "duration": 8.777086,
     "end_time": "2021-05-18T03:49:54.764673",
     "exception": false,
     "start_time": "2021-05-18T03:49:45.987587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name='Cendekia'\n",
    "print(\"Building model with\", base_model)\n",
    "model = tf.keras.Sequential([\n",
    "            # Note the input shape is the desired size of the image 128x128 with 3 bytes color\n",
    "            # This is the first convolution\n",
    "            base_model,\n",
    "            tf.keras.layers.Conv2D(filters=32, padding='same', kernel_size=3, activation='relu', strides=1),\n",
    "            tf.keras.layers.MaxPool2D(pool_size=2, strides=2),\n",
    "            tf.keras.layers.Dropout(rate=0.5),\n",
    "\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(20, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=.001), loss=['categorical_crossentropy'], metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279b827c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15c1ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs =100\n",
    "\n",
    "history = model.fit(train_gen, epochs=epochs, validation_data=test_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "downtown-anxiety",
   "metadata": {
    "papermill": {
     "duration": 0.048737,
     "end_time": "2021-05-18T03:49:45.729278",
     "exception": false,
     "start_time": "2021-05-18T03:49:45.680541",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### define function to print text in RGB foreground and background colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passing-cancellation",
   "metadata": {
    "papermill": {
     "duration": 0.059338,
     "end_time": "2021-05-18T03:49:45.837831",
     "exception": false,
     "start_time": "2021-05-18T03:49:45.778493",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_in_color(txt_msg,fore_tupple,back_tupple,):\n",
    "    #prints the text_msg in the foreground color specified by fore_tupple with the background specified by back_tupple \n",
    "    #text_msg is the text, fore_tupple is foregroud color tupple (r,g,b), back_tupple is background tupple (r,g,b)\n",
    "    rf,gf,bf=fore_tupple\n",
    "    rb,gb,bb=back_tupple\n",
    "    msg='{0}' + txt_msg\n",
    "    mat='\\33[38;2;' + str(rf) +';' + str(gf) + ';' + str(bf) + ';48;2;' + str(rb) + ';' +str(gb) + ';' + str(bb) +'m' \n",
    "    print(msg .format(mat), flush=True)\n",
    "    print('\\33[0m', flush=True) # returns default print color to back to black\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usual-lounge",
   "metadata": {
    "papermill": {
     "duration": 0.066176,
     "end_time": "2021-05-18T04:03:53.391639",
     "exception": false,
     "start_time": "2021-05-18T04:03:53.325463",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### define function to plot the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "going-efficiency",
   "metadata": {
    "papermill": {
     "duration": 0.08383,
     "end_time": "2021-05-18T04:03:53.540249",
     "exception": false,
     "start_time": "2021-05-18T04:03:53.456419",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tr_plot(tr_data, start_epoch):\n",
    "    #Plot the training and validation data\n",
    "    tacc=tr_data.history['accuracy']\n",
    "    tloss=tr_data.history['loss']\n",
    "    vacc=tr_data.history['val_accuracy']\n",
    "    vloss=tr_data.history['val_loss']\n",
    "    Epoch_count=len(tacc)+ start_epoch\n",
    "    Epochs=[]\n",
    "    for i in range (start_epoch ,Epoch_count):\n",
    "        Epochs.append(i+1)   \n",
    "    index_loss=np.argmin(vloss)#  this is the epoch with the lowest validation loss\n",
    "    val_lowest=vloss[index_loss]\n",
    "    index_acc=np.argmax(vacc)\n",
    "    acc_highest=vacc[index_acc]\n",
    "    plt.style.use('fivethirtyeight')\n",
    "    sc_label='best epoch= '+ str(index_loss+1 +start_epoch)\n",
    "    vc_label='best epoch= '+ str(index_acc + 1+ start_epoch)\n",
    "    fig,axes=plt.subplots(nrows=1, ncols=2, figsize=(20,8))\n",
    "    axes[0].plot(Epochs,tloss, 'r', label='Training loss')\n",
    "    axes[0].plot(Epochs,vloss,'g',label='Validation loss' )\n",
    "    axes[0].scatter(index_loss+1 +start_epoch,val_lowest, s=150, c= 'blue', label=sc_label)\n",
    "    axes[0].set_title('Training and Validation Loss')\n",
    "    axes[0].set_xlabel('Epochs')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].legend()\n",
    "    axes[1].plot (Epochs,tacc,'r',label= 'Training Accuracy')\n",
    "    axes[1].plot (Epochs,vacc,'g',label= 'Validation Accuracy')\n",
    "    axes[1].scatter(index_acc+1 +start_epoch,acc_highest, s=150, c= 'blue', label=vc_label)\n",
    "    axes[1].set_title('Training and Validation Accuracy')\n",
    "    axes[1].set_xlabel('Epochs')\n",
    "    axes[1].set_ylabel('Accuracy')\n",
    "    axes[1].legend()\n",
    "    plt.tight_layout\n",
    "    #plt.style.use('fivethirtyeight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precise-veteran",
   "metadata": {
    "papermill": {
     "duration": 0.064531,
     "end_time": "2021-05-18T04:03:53.669838",
     "exception": false,
     "start_time": "2021-05-18T04:03:53.605307",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### define function to generate the confusion matrix and classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cheap-latino",
   "metadata": {
    "papermill": {
     "duration": 0.09055,
     "end_time": "2021-05-18T04:03:53.825558",
     "exception": false,
     "start_time": "2021-05-18T04:03:53.735008",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_info( test_gen, preds, print_code, save_dir, subject ):\n",
    "    class_dict=test_gen.class_indices\n",
    "    labels= test_gen.labels\n",
    "    file_names= test_gen.filenames \n",
    "    error_list=[]\n",
    "    true_class=[]\n",
    "    pred_class=[]\n",
    "    prob_list=[]\n",
    "    new_dict={}\n",
    "    error_indices=[]\n",
    "    y_pred=[]\n",
    "    for key,value in class_dict.items():\n",
    "        new_dict[value]=key             # dictionary {integer of class number: string of class name}\n",
    "    # store new_dict as a text fine in the save_dir\n",
    "    classes=list(new_dict.values())     # list of string of class names\n",
    "    dict_as_text=str(new_dict)\n",
    "    dict_name= subject + '-' +str(len(classes)) +'.txt'  \n",
    "    dict_path=os.path.join(save_dir,dict_name)    \n",
    "    with open(dict_path, 'w') as x_file:\n",
    "        x_file.write(dict_as_text)    \n",
    "    errors=0      \n",
    "    for i, p in enumerate(preds):\n",
    "        pred_index=np.argmax(p)        \n",
    "        true_index=labels[i]  # labels are integer values\n",
    "        if pred_index != true_index: # a misclassification has occurred\n",
    "            error_list.append(file_names[i])\n",
    "            true_class.append(new_dict[true_index])\n",
    "            pred_class.append(new_dict[pred_index])\n",
    "            prob_list.append(p[pred_index])\n",
    "            error_indices.append(true_index)            \n",
    "            errors=errors + 1\n",
    "        y_pred.append(pred_index)    \n",
    "    if print_code !=0:\n",
    "        if errors>0:\n",
    "            if print_code>errors:\n",
    "                r=errors\n",
    "            else:\n",
    "                r=print_code           \n",
    "            msg='{0:^28s}{1:^28s}{2:^28s}{3:^16s}'.format('Filename', 'Predicted Class' , 'True Class', 'Probability')\n",
    "            print_in_color(msg, (0,255,0),(55,65,80))\n",
    "            for i in range(r):                \n",
    "                split1=os.path.split(error_list[i])                \n",
    "                split2=os.path.split(split1[0])                \n",
    "                fname=split2[1] + '/' + split1[1]\n",
    "                msg='{0:^28s}{1:^28s}{2:^28s}{3:4s}{4:^6.4f}'.format(fname, pred_class[i],true_class[i], ' ', prob_list[i])\n",
    "                print_in_color(msg, (255,255,255), (55,65,60))\n",
    "                #print(error_list[i]  , pred_class[i], true_class[i], prob_list[i])               \n",
    "        else:\n",
    "            msg='With accuracy of 100 % there are no errors to print'\n",
    "            print_in_color(msg, (0,255,0),(55,65,80))\n",
    "    if errors>0:\n",
    "        plot_bar=[]\n",
    "        plot_class=[]\n",
    "        for  key, value in new_dict.items():        \n",
    "            count=error_indices.count(key) \n",
    "            if count!=0:\n",
    "                plot_bar.append(count) # list containg how many times a class c had an error\n",
    "                plot_class.append(value)   # stores the class \n",
    "        fig=plt.figure()\n",
    "        fig.set_figheight(len(plot_class)/3)\n",
    "        fig.set_figwidth(10)\n",
    "        plt.style.use('fivethirtyeight')\n",
    "        for i in range(0, len(plot_class)):\n",
    "            c=plot_class[i]\n",
    "            x=plot_bar[i]\n",
    "            plt.barh(c, x, )\n",
    "            plt.title( ' Errors by Class on Test Set')\n",
    "    y_true= np.array(labels)        \n",
    "    y_pred=np.array(y_pred)\n",
    "    if len(classes)<= 30:\n",
    "        # create a confusion matrix \n",
    "        cm = confusion_matrix(y_true, y_pred )        \n",
    "        length=len(classes)\n",
    "        if length<8:\n",
    "            fig_width=8\n",
    "            fig_height=8\n",
    "        else:\n",
    "            fig_width= int(length * .5)\n",
    "            fig_height= int(length * .5)\n",
    "        plt.figure(figsize=(fig_width, fig_height))\n",
    "        sns.heatmap(cm, annot=True, vmin=0, fmt='g', cmap='Blues', cbar=False)       \n",
    "        plt.xticks(np.arange(length)+.5, classes, rotation= 90)\n",
    "        plt.yticks(np.arange(length)+.5, classes, rotation=0)\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Actual\")\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        plt.show()\n",
    "    clr = classification_report(y_true, y_pred, target_names=classes)\n",
    "    print(\"Classification Report:\\n----------------------\\n\", clr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separate-northern",
   "metadata": {
    "papermill": {
     "duration": 0.071455,
     "end_time": "2021-05-18T04:03:53.969331",
     "exception": false,
     "start_time": "2021-05-18T04:03:53.897876",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### evaluate model on the test set then save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "english-bachelor",
   "metadata": {
    "papermill": {
     "duration": 15.329191,
     "end_time": "2021-05-18T04:04:09.403286",
     "exception": false,
     "start_time": "2021-05-18T04:03:54.074095",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tr_plot(history,0)\n",
    "save_dir=r'./'\n",
    "subject='Batik Exception'\n",
    "acc=model.evaluate( test_gen, batch_size=test_batch_size, verbose=1, steps=test_steps, return_dict=False)[1]*100\n",
    "msg=f'accuracy on the test set is {acc:5.2f} %'\n",
    "print_in_color(msg, (0,255,0),(55,65,80))\n",
    "save_id=str (model_name +  '-' + subject +'-'+ str(acc)[:str(acc).rfind('.')+3] + '.h5')\n",
    "save_loc=os.path.join(save_dir, save_id)\n",
    "model.save(save_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sensitive-coverage",
   "metadata": {
    "papermill": {
     "duration": 0.117951,
     "end_time": "2021-05-18T04:04:09.640782",
     "exception": false,
     "start_time": "2021-05-18T04:04:09.522831",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### make predictions on test set and generate confusion matrix and classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "actual-fortune",
   "metadata": {
    "papermill": {
     "duration": 14.285038,
     "end_time": "2021-05-18T04:04:24.043800",
     "exception": false,
     "start_time": "2021-05-18T04:04:09.758762",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print_code=0\n",
    "preds=model.predict(test_gen) \n",
    "print_info( test_gen, preds, print_code, save_dir, subject )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65685c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 902.986742,
   "end_time": "2021-05-18T04:04:29.804901",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-05-18T03:49:26.818159",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
